# Zhan Bin (占彬)

## Profile

- Name: Zhan Bin (占彬)
- Phone: 180-1638-1485
- Email: 76626123@qq.com
- Address: Room 601, No. 55, Lane 879, Huanlin East Road, Pudong New Area
- Hometown: Shanghai
- Gender: Male

## Introduction

Passionate about learning with 20 years of development and management experience, specializing in web internet architecture construction, enterprise distributed system development, and AI/ML system design. Proficient in summarization and data modeling, with extensive practical experience in machine learning, deep learning, and computer vision. Holds Microsoft Azure Architect Expert certification and is proficient in .NET and Python ecosystems. Excellent code reading ability, able to quickly read and adapt to different development languages and platforms.

Broad technical stack, familiar with the entire enterprise data flow development process and AI/ML engineering workflow. From data model construction, machine learning model design, frontend to backend to data warehouse - a series of theoretical and technical applications. Possesses end-to-end AI system development capabilities, including data collection, model training, inference services, and system integration.

Enjoys problem-solving and scientific verification with an engineering mindset. Critical thinking, Problem solving, and Decision making.

Certifications: Azure Solutions Architect Expert and Microsoft Azure Administrator

Technical-oriented management, integrating Scrum habits and advantages, previously obtained Scrum Master certification.

---

## Skills

### Programming Languages & Frameworks
1. Proficient development languages: C#
2. Familiar development languages: JS, TypeScript, Python, Go, Java
3. Familiar with .NET Core
4. Frontend development: Familiar with JQuery, Angular, React Native (Expo)
5. Backend development: Familiar with WCF, ASP.NET MVC, WebAPI, Flask, Spring Boot, FastAPI
6. Mainstream ORM tools: Entity Framework
7. Mainstream IOC tools: Unity, etc.
8. Other platforms: SQLAlchemy, MyBatis

### Data Collection & Modeling
1. Use OLTP for data model design, analyze business requirements and data modeling, define dependencies between data models
2. Data flow processing: Use SQL or Databricks and other tools to ensure data quality in Data pipeline, such as data cleaning, data validation, etc.
3. Familiar with Data governance tools like Azure Purview

### Cloud Platforms & ETL Tools
1. Azure cloud for microservices: Familiar with Azure App Service, Azure Functions
2. ETL tool usage: Azure Data Factory, Azure Databricks
3. Understanding of cloud storage: Azure SQL Database, Azure Storage Account, Azure Cosmos DB and Azure Cache for Redis
4. Other databases: MySQL, PostgreSQL
5. Familiar with Key-vault security handling, etc.

### Data Analysis & Big Data
1. Use OLAP theory for dimension design based on business requirements
2. Use Databricks (Spark) and other tools for data lake development
3. Regular maintenance and archiving
4. Big data development: Apply Databricks for data development, understand RDD, Map, Shuffle, Reduce and other principles
5. Understanding of HDFS and HIVE

### Machine Learning & Deep Learning
1. Deep learning frameworks: PyTorch, TensorFlow, familiar with neural network architecture design, model training and optimization
2. Computer vision: YOLO object detection, human keypoint detection, attention mechanisms, image classification, bounding box detection
3. Model architecture design: ResNet, attention networks, multi-level Fallback mechanism, dynamic weight adjustment
4. Model optimization: inference acceleration, memory optimization, batch prediction, model deployment and service
5. Data processing: image preprocessing, data augmentation, feature engineering, data visualization

### Python Ecosystem
1. Scientific computing libraries: NumPy, Pandas, OpenCV, PIL, Matplotlib, Seaborn, scikit-learn
2. Web development enhancement: Flask advanced applications, WebSocket real-time communication, RESTful API design, frontend integration
3. System integration: multi-process processing, asynchronous programming, configuration management, logging systems, testing frameworks
4. Distributed systems & AI integration: LangChain, ChromaDB, sentence-transformers, unified interface for multiple LLM providers, advanced asynchronous programming, microservice design, unified master controller, modular architecture, intelligent caching, batch processing, memory management, concurrency control, system monitoring, containerized deployment, CI/CD processes, test-driven development, configuration management, error handling

### Database Technology
1. Data modeling: relational database design, data lineage tracking, metadata management
2. Vector databases: ChromaDB management, document vectorization, similarity retrieval, batch vector operations, performance optimization

### System Architecture & Engineering Practices
1. Design patterns: factory pattern, modular architecture, configuration-driven design
2. Quality assurance: unit testing, integration testing, performance testing, error handling
3. Project management: version control, documentation management, code standards, technical debt management

### RAG & Intelligent Q&A Technology
1. RAG system architecture: retrieval augmented generation, dual database design, semantic search engine, intelligent document creation
2. LangChain framework: Agent development, Tool integration, Memory management, multi-model collaboration, natural language processing
3. Intelligent matching algorithms: multi-dimensional scoring, dynamic weight adjustment, confidence calculation, semantic similarity analysis
4. System integration: unified LLM factory, adapter pattern, configuration-driven, error handling mechanisms

### Full-Stack Development & Mobile Applications
1. Mobile development: React Native (Expo), TypeScript, state management, offline synchronization
2. Backend development: FastAPI, SQLAlchemy, API design, authentication and authorization
3. Database design: SQLite, data modeling, performance optimization, dual database architecture
4. DevOps practices: Docker, Nginx, cloud service deployment, CI/CD processes

### AI/ML Application Development
1. LLM integration: OpenAI, Zhipu AI API integration and optimization
2. Prompt engineering: Prompt design and optimization, AI output quality control
3. AI system design: AI service architecture, state management, cost control
4. Intelligent application development: AI-driven user experience optimization and personalized services

### Independent Development Capability
1. Full-stack project management: end-to-end process management from requirements analysis to deployment and operations
2. Technical decision-making: independent technology selection, architecture design and implementation solution formulation
3. AI collaborative development: collaborate with AI for code generation, architecture design and documentation writing
4. Quality assurance: establish testing strategies, code review and quality control mechanisms

### Other Skills
1. Familiar with Azure IAAS, Alibaba Cloud ECS
2. Familiar with version management, documentation and automated deployment tools: SVN/Git
3. Familiar with using project management tools like JIRA
4. Payment system integration: redemption codes, Google Play and other multi-platform payments
5. Security design: JWT authentication, API rate limiting, parameter validation, payment security

---

## Responsibilities

1. Analyze customer requirements and conduct development assessments for each task, mainly evaluating the implementation of technical solutions
2. Project risk control
3. Architecture design, analyze project architecture based on company and project software environment, resources, team technology stack, etc., and perform project architecture upgrades and implementation according to customer requirements and future situations
4. Formulate technical requirements, responsible for refining technical tasks. Coordinate team and other resource usage
5. Risk management of technical solutions. Solve security issues, conduct phased upgrades for security requirements
6. Formulate project refactoring plans and implement them
7. Help project quality control. Assist teams in problem-solving, coordination and communication, promote communication and cooperation between teams, ensure goal consistency
8. Improve team efficiency and productivity
9. Independent development project management: as an independent developer, responsible for end-to-end process management from requirements analysis to deployment and operations
10. AI collaborative development: collaborate with AI for code generation, architecture design and documentation writing, exploring new development models of human-machine collaboration
11. Full-stack technical decision-making: independently responsible for technology selection, architecture design and implementation solution formulation
12. Innovative technology application: research and apply cutting-edge technologies, such as AI integration, mobile development, payment systems, etc.

---

## Professional Experience

### Zoetis (June 2023 – Present)

#### Project: MySixth Tarot Intelligent Application (October 2023 - Present)

**Project Overview:**
Personal independent developer project, a tarot application developed through personal + AI collaboration, including a complete solution with mobile app, backend API, management portal, and payment system.

**Project Challenges:**
1. As an independent developer, responsible for the entire process from requirements analysis to deployment and operations
2. Complex technology stack covering mobile, backend, database, payment systems and other fields
3. Need to design scalable architecture to support subsequent feature iterations and commercialization
4. Complex AI service integration, requiring handling multiple LLM providers and cost control

**Technical Architecture & Implementation:**
1. Designed and implemented complete full-stack architecture: React Native + FastAPI + SQLite + Docker
2. Innovatively designed two-step AI interpretation process (dimensional analysis → specific interpretation) to enhance user experience
3. Established complete offline synchronization mechanism, supporting full and incremental data updates
4. Implemented multilingual internationalization architecture, supporting seamless Chinese-English switching
5. Designed flexible payment system, supporting redemption codes and Google Play multi-platform payments

**Vibe Coding Practices & Code Quality:**
1. **Code Logic Completeness**: Designed modular architecture with single responsibility for each module, clear interfaces, ensuring code logic integrity and maintainability
2. **Coding Standards & Best Practices**: Strictly follow TypeScript and Python coding standards, use ESLint and Pylint for code quality checks, ensuring code style consistency
3. **Design Pattern Application**: Applied design patterns such as factory pattern, adapter pattern, observer pattern to improve code extensibility and reusability
4. **Error Handling Mechanisms**: Established comprehensive exception handling systems, including global error capture, logging, user-friendly error prompts
5. **Code Review & Refactoring**: Regular code reviews to identify technical debt, timely refactoring and optimization, maintaining code health

**Technical Innovation & Optimization:**
1. Developed unified LLM factory pattern, supporting seamless switching between Zhipu AI and OpenAI
2. Implemented anonymous user authentication system, lowering usage barriers
3. Established multi-layer security protection mechanisms, including API rate limiting, parameter validation, payment security
4. Optimized database performance, designed dual database architecture separating configuration and user data
5. Implemented containerized deployment, established complete CI/CD processes

**Project Outcomes:**
1. Successfully delivered production-ready full-stack application, supporting Android/iOS dual platforms
2. Established scalable technical architecture, laying foundation for subsequent commercialization
3. Implemented AI-driven intelligent interpretation features, improving user experience and retention rate
4. Established complete monitoring and operations system, ensuring stable system operation
5. **Excellent Code Quality**: Through strict coding standards and design pattern applications, achieved high-quality, maintainable codebase
6. **Vibe Development Mode Practice**: Successfully integrated modern development concepts into the project, demonstrating excellent ability to maintain code quality during rapid iterations
7. As a personal independent developer project, demonstrated full-stack technical capabilities and project management capabilities

**Technologies Used:**
React Native (Expo), FastAPI, SQLite, Docker, Nginx, Zhipu AI, OpenAI, LangChain, JWT, Alibaba Cloud ECS

---

#### Project: NGSE (Next Generation Sales Engine)

**Project Overview:**
In the NGSE project, I led the architecture design and development of the data platform for the China region, building a Databricks-based data processing and analysis platform from 0 to 1, supporting AI model training, business analysis, and multi-market data processing.

**Key Responsibilities:**
1. Data pipeline architecture design and implementation
2. Integration with Azure platform
3. Data quality and monitoring system construction
4. Performance optimization practices
5. Lakehouse architecture construction

**Technical Achievements:**
1. Built a four-layer data processing architecture (Inbox → Raw → Transform → Governed)
2. Utilized Databricks Workflows to implement task dependency management, breaking down processing into ingestion, cleansing, join, aggregation and other modules
3. Used Delta Lake to manage data versions and transaction consistency, implementing data rollback capability in batch processing mode
4. For full and incremental data update issues, designed automatic validation and difference comparison mechanism based on T-1 data timeliness
5. Wrote and optimized Spark SQL and PySpark scripts, developing a series of highly reusable public ETL modules
6. Implemented method registration mechanism and automatic loading of Hive SQL scripts, separating business logic from common code
7. Developed parameterized Notebook templates (combined with Widgets), supporting rapid deployment and reuse of multi-market data processing logic
8. Configured and managed Azure Data Factory (ADF) as upstream scheduling tool
9. Implemented cross-platform data transmission (Aliyun OSS → Azure Data Lake Storage Gen2) and cache management
10. Built data quality validation modules, including Schema Drift detection, field integrity checks, null value and duplicate value monitoring
11. For hotspot wide tables, implemented partitioning, Z-Ordering, cache configuration and dynamic aggregation layer pre-computation
12. Designed and implemented lakehouse architecture based on Databricks + Delta Lake, replacing traditional DWH solutions

**Technologies Used:**
Databricks, Delta Lake, Azure Data Factory, Azure Storage, Spark SQL, PySpark, Azure Functions

**Project Impact:**
- Significantly improved AI model training and BI report query performance, key report runtime improved by 2-3 times
- Established company-level data warehouse development standards, ensuring standardized, atomic, and modular development processes
- Implemented data quality validation and exception alert mechanisms, improving data reliability

---

#### Project: AI-Enhanced Intelligent Resume Submission System

**Project Overview:**
As a personal independent developer, designed and implemented an end-to-end intelligent resume submission system based on RAG technology and LangChain framework, demonstrating full-stack technical capabilities from AI system architecture to distributed system design.

**Key Responsibilities:**
1. Independently completed RAG-enhanced intelligent analysis system design and implementation
2. Independently completed LangChain Agent intelligent Q&A system development
3. Independently designed high-performance intelligent matching engine
4. Independently completed distributed system architecture and performance optimization
5. Independently implemented advanced Web automation and anti-crawler technology
6. Independently built unified LLM factory and multi-model integration
7. Independently completed system integration and engineering practices

**Technical Achievements:**
1. Built RAG system based on dual database architecture (SQLite + ChromaDB), achieving unified management of structured data and vectorized semantic information
2. Designed four-layer data processing architecture (Raw → Processing → Vector → Analysis), supporting complete process from raw job data to intelligent analysis
3. Based on sentence-transformers multilingual embedding model, achieved millisecond-level vector retrieval, supporting deep semantic understanding and similarity calculation of large-scale job data
4. Developed automatic document decomposition algorithm, intelligently decomposing job information into overview, responsibilities, requirements, skills and other semantic documents, improving retrieval accuracy by over 30%
5. Integrated LLM compression retriever, combined with Zhipu GLM-4-Flash model, achieving semantic associations and intelligent matching that traditional keyword searches cannot discover
6. Designed and implemented intelligent analysis Agent based on LangChain framework, integrating professional tools such as skill requirement analysis, salary analysis, trend analysis
7. Implemented deep application of STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION mode, supporting complex natural language queries and context understanding
8. Designed comprehensive scoring system including semantic similarity, skill matching, experience matching, industry matching, salary matching, with matching accuracy reaching 91.27%
9. Designed MasterController to coordinate end-to-end processes, achieving complete automation from job search, RAG processing, intelligent matching to automatic submission
10. Extensively used Python asyncio for high-concurrency processing, system processing speed reached job extraction >100/minute, RAG processing >50/minute
11. Developed BehaviorSimulator to simulate real user operations, including mouse movement trajectories, scrolling behavior, reading pauses, effectively avoiding anti-crawler detection
12. Designed unified LLM factory supporting Zhipu GLM, OpenAI, Claude, Ollama, achieving standardized model calling interfaces and seamless switching

**Technologies Used:**
LangChain, RAG, ChromaDB, sentence-transformers, Zhipu GLM-4, Python, asyncio, SQLite, Redis, Flask, Docker, pytest

**Project Impact:**
- System matching accuracy reached 91.27%, processing speed >100 jobs/minute
- Through innovative technical solutions and strict engineering practices, successfully built a production-ready intelligent system
- Injected AI-driven intelligent capabilities into traditional job search processes

---

#### Project: AI-Enhanced Image Crawler System (Image Crawler)

**Project Overview:**
Designed and implemented an intelligent image crawler system integrated with machine learning, demonstrating full-stack technical capabilities from system architecture to AI models.

**Key Responsibilities:**
1. Machine learning model design and optimization
2. System architecture design and implementation
3. Database design and optimization
4. Web interface and user experience development
5. Engineering practices and quality assurance
6. Performance optimization and innovation

**Technical Achievements:**
1. Designed and implemented ResNet50-based bounding box attention mechanism, reducing computational complexity by 67% and improving inference speed by 30% compared to traditional multi-region keypoint attention
2. Innovatively implemented three-level Fallback mechanism (keypoints → bounding box → full image attention), ensuring 95-100% sample utilization rate
3. Integrated YOLO-Pose for human keypoint detection, achieving intelligent image pre-filtering and improving data quality
4. Model validation accuracy reached 91.27%, successfully processed batch image prediction, inference service stability reached 100%
5. Adopted modular architecture and factory pattern, implementing highly scalable crawler system supporting multiple data sources and storage backends
6. Designed complete data pipeline: image collection → duplicate detection → ML prediction → data storage → web display
7. Implemented SHA-256-based content hash deduplication mechanism, avoiding duplicate downloads and saving over 20% storage space
8. Built unified ML inference service, supporting dynamic switching and hot updates of multiple models
9. Designed unified database architecture, integrating crawler data, ML prediction results and user annotations, supporting efficient queries
10. Developed fully functional web management interface based on Flask, supporting real-time data monitoring and interactive operations
11. Implemented WebSocket real-time updates, image gallery, SQL query interface, statistical dashboard and other features
12. Established complete testing framework, including unit tests and integration tests, with code coverage reaching over 85%

**Technologies Used:**
Python, PyTorch, YOLO, OpenCV, Flask, SQLite, HTML/CSS/JavaScript, RESTful API, WebSocket

**Project Impact:**
- This project demonstrated technical depth in the AI/ML field and full-stack development capabilities from requirements analysis to system implementation
- Through innovative attention mechanism design and engineering practices, successfully built a production-ready AI-enhanced system
- Injected intelligent capabilities into traditional crawler technology

---

### PWC (November 2016 – February 2023)

#### Project: Remedium (BI) (October 2016 – June 2018)

**Position:** Technical Team Lead

**Project Overview:**
Mainly responsible for solution architecture design and development, leading technical team to provide BI solutions for the pharmaceutical industry.

**Main Responsibilities:**
1. Solution Architecture Design: Led solution architecture design discussions and collaborated with European teams to develop robust architecture framework for the Remedium project
2. Data Pipeline Development: Supervised design and development of data pipelines using Azure Data Factory (ADF) and Databricks
3. Reporting and Analytics: Guided implementation of reporting and analytics layers, ensuring generation of accurate and actionable transactional data reports
4. Web Portal Design: Led design and development of Remedium web portal, aiming to improve review efficiency for PWC business personnel
5. Cross-functional Collaboration: Facilitated collaboration between technical teams, business stakeholders, and end users

**Main Achievements:**
1. Data Processing Optimization: Reduced processing time and improved data quality by implementing efficient data pipelines using ADF and Databricks
2. Reporting Capability Enhancement: Implemented reporting solutions to provide timely and insightful transactional data reports, improving visibility
3. Review Efficiency Improvement: Designed and deployed Remedium web portal, enabling business users to access data in real-time and effectively identify and resolve review issues
4. Satisfaction: Received positive feedback from stakeholders for delivering solutions that met business needs and promoted operational excellence in the pharmaceutical industry

**Technologies Used:**
Azure Data Factory, Databricks, BI tools, Web development technologies

---

#### Project: SMART (October 2016 – February 2023)

**Position:** Technical Team Lead

**Project Overview:**
The SMART project is a highly challenging project, mainly providing pre-approval for medical insurance. As the SMART project has been running for over 10 years, the business logic is complex.

**Main Responsibilities:**
1. Technical Design and Architecture: Led design and development of data models for OLTP and OLAP systems, ensuring scalability, performance, and following microservice architecture principles
2. ETL Architecture Redesign: Led redesign of Smart ETL layer architecture, integrating resource scheduling modules and distributed memory engine computing modules
3. Quality Control and Testing: Communicated test plans with testers, resolved testing issues, and facilitated performance testing
4. Risk Management: Implemented risk control measures, resolved code vulnerabilities, ensuring smooth security reviews
5. DevOps Implementation: Developed new CI/CD processes and integrated automated unit testing, improving development efficiency and code quality
6. Data Warehouse Maintenance: Responsible for maintaining data warehouse, ensuring data integrity, availability, and security
7. Security Upgrades: Collaborated with security team to regularly scan project code and develop remediation plans for identified vulnerabilities
8. Agile Development: Adopted agile development methodology for project management, promoting flexibility and response to changing requirements

**Main Achievements:**
1. High SLA Achievement: Successfully achieved 99.99% SLA by implementing robust technical architecture and optimization strategies
2. ETL Architecture Enhancement: Led ETL architecture redesign, improving data processing efficiency and performance
3. Quality Assurance Excellence: Ensured high-quality delivery through effective communication of test plans and proactive resolution of testing issues
4. Risk Mitigation and Security: Implemented risk control measures and security upgrades, enhancing project security and reducing vulnerabilities
5. DevOps Integration: Improved development efficiency and code quality by implementing CI/CD processes

**Technologies Used:**
OLTP, OLAP, ETL, CI/CD, Agile development, Security scanning tools

---

### HP (October 2010 - October 2016)

#### Project: LMS (October 2014 – October 2016)

**Position:** Leader and Scrum Master

**Project Overview:**
Mainly responsible for data management of the LMS ODS system. The LMS project's ODS system is one of the upstream systems of HP's EDW, mainly responsible for managing HP training and external company orders, training plans, and HP internal and external employee file information, etc.

**Main Responsibilities:**
1. Designed LMS system architecture, mainly responsible for developing API interfaces with SABA training system and real-time data synchronization
2. ETL layer development, used Informatica to customize scheduled tasks, analyzed mapping relationships, developed data flows
3. SCRUM Master: Responsible for helping team refine tasks, organize meetings, conduct project reviews
4. Resolved team conflict issues, made decisions based on understanding and experience of architecture design and business logic

**Main Achievements:**
1. Developed a monitoring service to quickly analyze, troubleshoot, and locate interface issues, ensuring interface stability
2. Incrementally extracted Saba database data to ODS, improving data synchronization efficiency
3. Organized a 20-person resource group into a 6-person development team, including interface development team, ETL and ODS business development team, and testing development team
4. Implemented parallel development tasks, set priorities for each task, ensuring delivery continuity between sprints

**Technologies Used:**
SABA training system, Informatica, ETL, Scrum, API development

---

#### Project: Move To HP Cloud (October 2012 – October 2014)

**Position:** Senior Developer II

**Project Overview:**
Migrated HP internal projects to the cloud, main responsibilities included building project infrastructure and performing upgrades/testing based on project architecture design, utilizing IAAS services provided by HP cloud.

**Main Responsibilities:**
1. Infrastructure Construction: Created virtual networks, configured internal gateways or firewalls, created and set up load balancers and created virtual machines, etc.
2. Development, testing and production environment installation and upgrades
3. Integrated other SAAS provided internally by HP into existing projects
4. Assisted with integration testing and regression testing
5. Helped resolve various technical issues encountered in the project

**Technologies Used:**
HP cloud IAAS services, Virtual networks, Load balancing, SAAS integration

---

#### Project: Customer Insight (October 2010 – October 2014)

**Position:** Development and Design

**Project Overview:**
Based on previous HP users' server configuration solutions, provided intelligent configuration to help guide customers quickly complete a set of server architecture solutions.

**Main Responsibilities:**
1. Configuration algorithm design and development
2. Customer preference design, such as price optimization, performance maximization, or based on professional configuration architecture, platform architecture, or customer historical records, etc.
3. Different preferences correspond to different data statistical results, statistical results regularly generated from database
4. Through preference configuration sets, used UI to guide customers in configuration
5. Report development, provided analysis reports, designed different preferences based on reports and implemented them

**Main Achievements:**
1. Implemented intelligent server configuration solutions, improving customer configuration efficiency
2. Developed preference-based configuration algorithms, supporting multiple optimization strategies
3. Established complete data statistics and reporting system, supporting decision analysis

**Technologies Used:**
Configuration algorithms, Database, UI development, Reporting systems

---

### Other

#### ATA (October 2008 – October 2010) Shanghai
Mainly responsible for maintaining securities personnel system, ATA's bank and securities qualification examination platform. Also responsible for CRM system development work.

#### Baodian Information (February 2006 – October 2008) Shanghai
Mainly responsible for electronic mobile e-commerce platform and forum architecture development design and Restful service development. (At that time, mobile was still in the 2G era, the internet era was just emerging, technically very innovative)

#### Shanda Network (November 2004 – November 2005) Shanghai
Developed Legend forum. High concurrent online user volume, participated in architecture design and development.

#### Bus Network Co., Ltd. (June 2003 – November 2004) Shanghai
Developed company's OA system.

---

## Education

Jiangsu University of Science and Technology (East China Shipbuilding Institute)
Bachelor's degree in Computer and Applications

---

## Certification

1. Microsoft Certified: Microsoft Azure Administrator
2. Microsoft Certified: Azure Solutions Architect Expert
3. Scrum Master
4. Certificate link: https://www.credly.com/badges/70eed59e-9ac9-4780-8dc5-313f87a94f8e/public_url